@uref{mailto:kvandoel@@xs4all.nl,Kees van den Doel}



@subsection Summary



Simulations were performed to establish the relation between the rating
difference (@strong{R}) between backgammon players of various strengths, and the
error rates for the two players. This will allow a match analysis to translate
the error rate of each player into an estimation of the absolute ratings of the
players, once the rating of &quot;perfect play&quot; has been defined. Of
course, this estimate will be only as good as the quality of the analysis and
will become invalid for the estimation of the rating of players at a comparable
level as at which the analysis was performed. However, the measured relation
does not depend on the analysis level and remains valid for very high levels of
analysis such as rollouts. 


Two sets of simulations were performed. In the first the relation between
the difference in normalized error rate per unforced decision (@strong{DEPD}) and
rating difference @strong{R} was measured. The main result of the first
simulation set is an almost linear relation between @strong{DEPD} and @strong{R},
which depends somewhat on the match length. As a by-product of this
investigation the relative strengths of various playing levels of GNUBG were
determined precisely by rating. 


The second set of simulations attempts to improve on the linear model of the
first set, by separating out the effects of cube errors and chequer play
errors. A bilinear fit was made of @strong{R} to both the normalized chequer play
error per unforced move (@strong{EPM}) and the cube error per unforced cube
decision (@strong{EPC}). The resulting bilinear fit is shown to improve the
prediction of the rating difference, especially for matches with very poor cube
handling compared to chequer play.


The scripts used for the simulations and a readme file explaining their use
are available 
@uref{http://www.cs.ubc.ca/~kvdoel/tmp/ratings/gnubgScripts.zip,here}.


The final result is the following formula for the rating difference:@*@strong{R = a2(N)*EPM+b(N)*EPC},@*
where@*@strong{a2(N) = 8798 + 25526/N},@*
and@*@strong{b(N) = 863 - 519/N}. 

@section Part I: Rating and DEPD


@subsection Introduction



In order to estimate the rating difference between playing levels we played
a series of 1000 matches of a given match length between various levels and
estimated the rating difference by analyzing the results. From the analysis we
obtain the normalized error rate per unforced decision and the &quot;luck
adjusted result&quot; (@strong{P}), which is an estimate of the match winning
probability using variance reduction. These numbers were averaged over the 1000
matches and the variance was also estimated. The rating difference @strong{R} and
a 90% confidence interval was then estimated from the 90% confidence interval
of @strong{P} using the FIBS rating formula, @strong{P = 1/(1 + 10^(R*sqrt(N)/2000))},
with @strong{N} the match length. 


Simulations were performed for match lengths of 1, 3, 5, 7, 11, and 23. For
practical reasons it was necessary to perform the error and luck analysis at
0-ply (expert level of GNUBG) and consider only levels at the expert level
(0-ply) and below (0-ply with noise addition). Equal noise was generated for
chequer play and for cube decisions. The following levels (0-ply with given
noise) were paired:


@multitable @columnfractions 0.33 0.33
@item @strong{player 1}
@tab @strong{player 2} 
@item 0
@tab 0.005
@item 0  
@tab 0.015
@item 0
@tab 0.02
@item 0  
@tab 0.04  
@item 0  
@tab 0.06  
@item 0.04 
@tab 0.06  
@item Level pairings 
@end multitable  
 


The assumption that the rating difference between players depends only
on @strong{DEPD} 
and not on the absolute level of play was verified implicitly with this choice
as the last pairing has both players with noise addition. If the
absolute @strong{EPD} 
mattered the last pairing would give results inconsistent with the first five,
which is not the case except for 1pt matches where as described in the results
section. 


With these settings, the simulation took about 100 hours on a 950Mhz Pentium
III. Simulations were performed on Windows XP, using GAWK and sh scripts within
the GNU ULTILS in combination with the no-GUI version of GNUBG (build 03 08
07). They should work equally well on LINUX. 


Three AWK scripts are used to create GNUBG scripts to play a given number of
matches, analyze them, and to collect statistics. Separate scripts were used in
order to modularize the tasks so the simulation can be interrupted and
continued without loss of data. The resulting match statistics were then
processed trough a fourth AWK script which computes the average rating @strong{R},
and the average @strong{DEPD} over the set, as well as the 90% confidence
intervals as estimated for a variance estimation. The levels of the players and
the analysis level is set in the .gnubgautorc file, outside the scripts.
Further analysis was then performed in MATLAB. 

@subsection Results



The results of the simulations are given in the figure below for all
match lengths. 

@html
@image{rall}
@strong{R} versus @strong{DEPD} for various match lengths
@end html
  
More detailed results are given in the figures below for each specific
match length. The measured data points are indicated by the
circles. The red line is a piecewise linear interpolation through the
data points. The black lines indicate the 90% confidence interval. The
green line is a least square fit through the data points (minimizing
the sum of squares of absolute rating differences) 

@html
@image{r3}
3pt match 

@image{r5}
5pt match 
  
@image{r7}
7pt match 
  
@image{r11}
11pt match 
  
@image{r23}
23pt match 
  
@image{r1}
1pt match 
@end html
 


For all match length except 1, the linear fit seems quite good and we can
approximate the rating difference by @strong{R= a(N)*DEPD}, where
@strong{N} is the match length. The function @strong{N*a(N)} is
plotted in the figure below, along with a linear least square fit. 

@html
@image{lsqcoeff}
Coefficient @strong{N*a(N)} versus match length 
@end html
  
The linear fit of @strong{N*a(N)} gives the following rating
formula:@*@strong{R = (11971 + 23681/N) * DEPD}. @* In the figure
below the formula is plotted along with the actual data points;  

@html
@image{rallfitted}
@end html
  
Rating versus @strong{DEPD} approximated by @strong{R = (11971 +
23681/N) * DEPD}. The dotted lines are the prediction, the solid lines
are piecewise linear segments through the data. 
  
The bump in the curve for the 1pt match around @strong{DEPD=0.015} is
caused by the data point from the @strong{0.04 - 0.06} (intermediate -
beginner). Apparently the approximation that the rating difference
does not depend on the absolute values of the error rates is less
accurate for 1pt matches.  


Note that, for the purpose of measuring @strong{DEPD} between simulated
players, it is a reasonable approximation to analyze a match at expert level if
both players are playing at expert level or worse. This is because we are only
interested in the difference between the error rates. When a match is
re-analyzed at World Class level (2-ply) the individual error rates increase,
but the difference remains approximately constant. To verify this explicitly,
we ran 2 sets of 40 matches between 0-ply expert level and 0-ply advanced level
(.015 noise) and analyzed them both at 0-ply and at 2-ply. The results
are given in the table below. 


@multitable @columnfractions 0.33 0.33
@item @strong{0-ply}
@tab @strong{2-ply}
@item 0.0075
@item 0.0068
@item 0.0080
@item 0.0072
@end multitable
2-ply versus 0-ply @strong{DEPD} testimates 
  
 


We see that the error in the 0-ply estimation appears to be in the order of 5%.
As an additional verification, a set of 100 3 pt matches was played between the
World Class level (2-ply) and the expert level which was analyzed at 2-ply. It
was found that the resulting @strong{DEPD} and rating difference @strong{R} was
well predicted by the model. The data point is indicated by the 'X' on the
figure for the 3pt match above and fits well on the curve. 

@subsection Conclusions



The data is well approximated by a linear relation between rating
difference and error per decision difference of the form
@strong{R=a(N)*DEPD} where @strong{N} is the match length. An
excellent approximation for @strong{a(N)} is @strong{a(N) = 23681/N +
11971}. The approximation is worst for @strong{N=1}. The assumption
that @strong{R} does not depend on the absolute @strong{EPD} but only
on the difference was validated, except for @strong{N=1}. The
assumption that@strong{DEPD} for matches between players at or below
the GNUBG expert level can we approximated by a 0-ply analysis was
verified by re-analyzing some matches at 2-ply with small effect on
the @strong{DEPD}. An explicit simulation of a series of 2-ply versus
0-ply matches resulted in an estimated @strong{R} which fitted the
model very well, supporting the assumption that the linear relation
between @strong{R} and @strong{DEPD} is valid for any level of
analysis.  

@section Part II: Rating and EPM and EPC


@subsection Introduction



In the above we have assumed that the rating depends only on@strong{DEPD = (totMoveErrors + totCubeErrors)/totalDecisions}. In reality the
rating difference will depend on some combination of chequerplay skill and cube
skill, at which the above formula makes an educated guess. A more powerful
predictor taking into account the separate effect of cube errors and
chequerplay errors can be obtained by simulating matches with independently
varied cube and chequerplay noise and fitting the rating by a bilinear form @strong{R=
a2(N)*EPM +b(N)*EPC}, with @strong{EPC = moverErr/unforcedMoves} and @strong{EPC=cubeErr/unforcedCubeDecisions}.


For match lengths of 3, 5, 7, 11, and 23, 500 matches between GNUBG 0-ply
and GNUBG 0-ply with 16 different noise settings were played. The chequer play
noise settings were @strong{0, 0.02, 0.04, 0.06} and the cube play noise settings
were @strong{0.05, 0.1, 0.4, 0.8}, 16 combinations in total. For each set of 500
matches the @strong{EPM} and @strong{EPC} were averaged. The rating difference was estimated as
in Part I by using the luck adjusted result.




For each match length the 16 data points were fitted to @strong{R = a2(N)*EPM
+b(N)*EPC} with a least square method, minimizing the squares of the rating
differences. For @strong{N=1} there are no cube decisions and @strong{a2(1) = a(1) = 37916}. 



@subsection Results



In the figures, below, we plot @strong{R} against @strong{DEPD}.
The green &quot;O&quot; indicates the measure rating differences, the green
dots the 90% confidence interval of the data, the red &quot;X&quot; indicates
the linear fit using the formula from Part I, and the blue &quot;X&quot;
indicates the prediction from the bilinear fit with the coefficients a2 and b as
indicated. 

@html
@image{d3}
Measurements and fit for match length 3. 

@image{d5}
Measurements and fit for match length 5. 
  
@image{d7}
Measurements and fit for match length 7. 
  
@image{d11}
Measurements and fit for match length 11. 

@image{d23}
Measurements and fit for match length 23. 
@end html
  
The coefficients @strong{a2(N)} and @strong{b(N)} as a function of
match length are well approximated by a linear function of
@strong{1/N}. We show these coefficients and a linear fit in the two
figures below.  

@html
@image{fita2}
Fitting @strong{Na2(N)} with  a linear function. 
  
@image{fitb}
Fitting @strong{Nb(N)} with a linear function.  
@end html
  
 

@subsection Conclusions



The bilinear fit improves the linear fit especially for
large cube errors. Usually the linear estimate is too high, reflecting too much
weight given to the cube errors, for which the bilinear formula corrects. The
data is well approximated by@*@strong{R = a2(N)*EPM+b(N)*EPC},@*
where@*@strong{a2(N) = 8798 + 25526/N},@*
and@*@strong{b(N) = 863 - 519/N}.

@subsection Appendix: Misc. measurements

@multitable @columnfractions 0.1 0.1 0.1 0.1 0.1 0.1 0.1
@item @strong{Player1}
@tab @strong{Player2}
@tab @strong{Match length}
@tab @strong{R1-R2}
@tab @strong{DEPD (e2-e1)}
@tab @strong{EPM}
@tab @strong{EPC}
@item expInt
@tab intExp
@tab 5pt  
@tab 472 [451 493]
@tab --
@tab -0.0344
@tab -0.01
@item expBeg
@tab advExp  
@tab 5pt
@tab 115 [103 127]
@tab --
@tab -0.00865
@tab +0.0176
@item expExp
@tab expBeg
@tab 5pt
@tab 31 [21 41]
@tab --
@tab 0
@tab -0.0185
@item expExp
@tab expBeg
@tab 11pt
@tab 29 [23 36]
@tab --
@tab 0
@tab -0.0165
@item expExp
@tab expBeg2 (1.0 cubenoise)
@tab 5pt
@tab 191 [176 206]
@tab --
@tab 0
@tab -0.192
@item wclassWclass
@tab wclassExp
@tab 5pt
@tab 6 [-15 27]
@tab --
@tab --
@tab --
@item 1-ply
@tab 0-ply
@tab 5pt
@tab 13 [-4 30]
@tab --
@tab --
@tab --
@end multitable

Some misc.  measurements. expBeg for example means chequer play at
level expert, cubeplay at level beginner. Rating interval is the 90%
confidence interval.  








